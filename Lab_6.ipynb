{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjAiDG4vrPJ660a7/jiaT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rochit02/ML-lab/blob/main/Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NxuDo8qFfRx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from collections import Counter\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILEPATH = 'hdd_dataset.csv'\n",
        "try:\n",
        "    df = pd.read_csv(FILEPATH)\n",
        "    features = ['capacity_bytes', 'is_legacy_format', 'smart_1_normalized', 'smart_1_raw']\n",
        "    target = 'failure'\n",
        "\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X = imputer.fit_transform(df[features])\n",
        "    y = df[target].values.astype(int)  # classification target\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    print(\"Data loaded successfully!\")\n",
        "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{FILEPATH}' not found\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "RcZqM5FaJArA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def equal_width_binning(values, bins=4):\n",
        "    \"\"\"Convert continuous values to categorical bins (equal width).\"\"\"\n",
        "    binned = pd.cut(values, bins=bins, labels=False)\n",
        "    return binned\n",
        "\n",
        "def entropy(y):\n",
        "    \"\"\"Calculate entropy of labels y.\"\"\"\n",
        "    counts = np.bincount(y)\n",
        "    probabilities = counts / len(y)\n",
        "    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "\n",
        "print(\"\\nA1: Entropy of target (failure)\")\n",
        "print(\"Entropy:\", entropy(y))\n"
      ],
      "metadata": {
        "id": "oYnEI4NcJCu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_index(y):\n",
        "    \"\"\"Calculate Gini index of labels y.\"\"\"\n",
        "    counts = np.bincount(y)\n",
        "    probabilities = counts / len(y)\n",
        "    return 1 - np.sum(probabilities**2)\n",
        "\n",
        "print(\"\\nA2: Gini Index of target (failure)\")\n",
        "print(\"Gini Index:\", gini_index(y))\n"
      ],
      "metadata": {
        "id": "n-To1BY2JEj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(y, x):\n",
        "    \"\"\"Calculate information gain for feature x.\"\"\"\n",
        "    base_entropy = entropy(y)\n",
        "    values = np.unique(x)\n",
        "    weighted_entropy = 0\n",
        "    for v in values:\n",
        "        subset_y = y[x == v]\n",
        "        weighted_entropy += (len(subset_y) / len(y)) * entropy(subset_y)\n",
        "    return base_entropy - weighted_entropy\n",
        "\n",
        "def best_feature_to_split(X, y, binning='equal_width', bins=4):\n",
        "    \"\"\"Select feature with max info gain (root node).\"\"\"\n",
        "    gains = {}\n",
        "    for i in range(X.shape[1]):\n",
        "        if np.issubdtype(X[:, i].dtype, np.number):\n",
        "            if binning == 'equal_width':\n",
        "                x_binned = equal_width_binning(X[:, i], bins=bins)\n",
        "            else:\n",
        "                est = KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='quantile')\n",
        "                x_binned = est.fit_transform(X[:, [i]]).astype(int).ravel()\n",
        "        else:\n",
        "            x_binned = X[:, i]\n",
        "        gains[i] = information_gain(y, x_binned)\n",
        "    return max(gains, key=gains.get), gains\n",
        "\n",
        "best_feature, gains = best_feature_to_split(X, y)\n",
        "print(\"\\nA3: Best feature for root node (by Info Gain):\", features[best_feature])\n",
        "print(\"Info Gains:\", gains)\n"
      ],
      "metadata": {
        "id": "CxFyiFI3JGhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nA5: Decision Tree trained!\")\n"
      ],
      "metadata": {
        "id": "M6AC-y8uJIYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plot_tree(clf, feature_names=features, class_names=[\"No Failure\", \"Failure\"],\n",
        "          filled=True, rounded=True)\n",
        "plt.title(\"Decision Tree Visualization\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WDYY0STQJJ49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "X_two = X_train[:, :2]  # use first 2 features\n",
        "y_two = y_train\n",
        "clf_two = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, random_state=42)\n",
        "clf_two.fit(X_two, y_two)\n",
        "\n",
        "x_min, x_max = X_two[:, 0].min() - 1, X_two[:, 0].max() + 1\n",
        "y_min, y_max = X_two[:, 1].min() - 1, X_two[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max-x_min)/200),\n",
        "                     np.arange(y_min, y_max, (y_max-y_min)/200))\n",
        "\n",
        "Z = clf_two.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.4)\n",
        "plt.scatter(X_two[:, 0], X_two[:, 1], c=y_two, cmap=cmap_bold, edgecolor='k', s=30)\n",
        "plt.xlabel(features[0])\n",
        "plt.ylabel(features[1])\n",
        "plt.title(\"Decision Boundary (Decision Tree with 2 features)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YD8PSIDsJLHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}